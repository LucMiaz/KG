\subsection{Reproducing the calculations}
The following calculations are done by calling data stored in a neo4j graph database from R. To insert data in this database, first use {\tt main\_ analysis.py} to generate a serie of json file containing all the useful info on your new data. Then use the code {\tt toDB.py} to import these data in the neo4j database -- before running the script, please read the head lines and make the necessary changes described there.

In R, the database is called as follows -- don't forget to launch the neo4j interface and start the local server if necessary :

<<Call of the database>>=
library(RNeo4j)#call RNeo4j package
graph=startGraph('http://localhost:7474/db/data', username='neo4j', password='admin')#opens a port to the db, with username 'neo4j' and password 'admin'
#to access the database click this link : 'http://neo4j:admin@localhost:7474/db/data'
@

\subsubsection{Structure of the database}

The databases in Neo4j are graphs, containing nodes and relationships between these nodes. Nodes and relationships have types (or labels). This will differentiate between Passings and Algorithms, in the case of Nodes, and between the relation of seeing (Passing saw this type of train) and the relation of taking place there (Passing took place here). To gain insight of this database please look at figure \ref{fig:neo4jdb} and at the structure in appendice {\ref{ssec:app:neo4jstruct}} on page {\pageref{ssec:app:neo4jstruct}}.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{img/graph.pdf}
\label{graphneo4j}
\caption{Illustration of the nodes and relationships types in the Neo4j database.}
\label{fig:neo4jdb}
\end{figure}

\subsection{Getting started in R}

We will import the measurements for all the algorithms. RNeo4j accepts {\tt data.frames} as input, so we will give it that. In the following R-code, we will call all evaluations made with the algorithms in the database, all Passings attached to those evaluations and all trains types of those Passings.

<<Data query>>=
query='
MATCH (p:Passing) 
MATCH (a)<-[e:EVALWITH]-(m)-[i:ISMICOF]->(p)-[s:SAW]->(t) 
RETURN a.Name, p.Name, p.Measurement, e.tNoisemasked_p, e.tNoisemasked, e.tNoise, m.tEval, m.tEvalmasked, m.tEvalmaskedp , t.Name, s.TrainLength
'
q<-cypher(graph,query)#takes the info of each MicMes for one algorithm
@
<<arrage, echo=FALSE>>=
q<- q %>% arrange(a.Name)
@
<<Evalsummary, echo=FALSE, results='asis'>>=
summarytable<-function(qt){
te<-summary(qt$m.tEval)
tn<-summary(qt$e.tNoise)
tem<-summary(qt$m.tEvalmasked)
tnm<-summary(qt$e.tNoisemasked)
temp<-summary(qt$m.tEvalmaskedp)
tnmp<-summary(qt$e.tNoisemasked_p)
sum.Names<-c('tEval','tNoise','tEvalmask.','tNoisemasked','tEvalmasked p','tNoisemasked p')
sum.min<-c(te[[1]],tn[[1]],tem[[1]],tnm[[1]],temp[[1]],tnmp[[1]])
sum.fsq<-c(te[[2]],tn[[2]],tem[[2]],tnm[[2]],temp[[2]],tnmp[[2]])
sum.med<-c(te[[3]],tn[[3]],tem[[3]],tnm[[3]],temp[[3]],tnmp[[3]])
sum.mean<-c(te[[4]],tn[[4]],tem[[4]],tnm[[4]],temp[[4]],tnmp[[4]])
sum.tsq<-c(te[[5]],tn[[5]],tem[[5]],tnm[[5]],temp[[5]],tnmp[[5]])
sum.max<-c(te[[6]],tn[[6]],tem[[6]],tnm[[6]],temp[[6]],tnmp[[6]])
return(data.frame('Name'=sum.Names,'Min'=sum.min,'fqu'=sum.fsq,'Median'=sum.med,'Mean'=sum.mean,'tqu'=sum.tsq,'Max'=sum.max))}
qcte <- q %>% group_by(a.Name, p.Measurement) %>% do(summarytable(.))
qcte$a.Name<- paste('Z2',gsub("^.*?_","_",qcte$a.Name), sep='')
qcte$thd_dB<- as.double(gsub('dB','',gsub("^.*Hz_",'', qcte$a.Name)))
qcte$fc_Hz<- as.integer(gsub('^.*s_','',sub("Hz_.*$",'', qcte$a.Name)))
qcte$dt_s<-as.double(gsub('Z2_*','',sub('s_.*$','',qcte$a.Name)))
qcte$p.Measurement <- NULL
qcte$a.Name<-NULL
qcte <-  data.frame('dt'=qcte$dt_s, 'fc'=qcte$fc_Hz, 'thd'=qcte$thd_dB, 'Name'=qcte$Name, 'min'=qcte$Min, 'fqu'=qcte$fqu, 'median'=qcte$Median, 'mean'=qcte$Mean, 'tqu'=qcte$tqu, 'max'=qcte$Max)
@
\begin{table}
\centering
\begin{tabular}{r|r|r|l|r|r|r|r|r|r}
$\delta$ & fc & thd & Name & Min. & 1st Qu. & Median & Mean & 3rd Qu. & Max. \\
<<Noisesummary, echo=FALSE, results='asis'>>=
tabqNoise <- xtable(qcte, digits=c(2),caption='Summary of the evaluated time.', label='tab:Noise')
print(tabqNoise, include.rownames = FALSE, include.colnames=FALSE, only.contents = TRUE)
@
\end{tabular}
\caption{Summary of the detected Noise and evalutation time (masked, p-masked and unmasked).}
\label{tab:tNoiseSummary}
\end{table}

We will perform a calculation to see if train type is a factor of the noise length (only on the measures made without lubrification, i.e. {\it Vormessung}).

<<trainfactor, result='asis', fig.cap='Ratio of Noisemasked'>>=
library(RColorBrewer)
qfilt<- q %>% filter(p.Measurement=='Vormessung')
ggplot(qfilt, mapping=aes(x = t.Name, y = e.tNoisemasked/m.tEvalmasked), lw=0)+geom_boxplot(outlier.colour = NULL, weight=0,size=0,notchwidth = 0.25, aes(fill=a.Name), linewidth=0)+
  #stat_summary(geom = "crossbar", width=0.65, fatten=0, color="white", fun.data = function(x){ return(c(y=median(x), ymin=median(x), ymax=median(x))) })+#prints the median. But must be changed to support the two algorithms. See http://biochemres.com/beautiful-minimalist-boxplots-with-r-and-ggplot2
  xlab('Train Type')+
  ylab('Ratio Noisemasked-Totalmasked')+
  coord_flip()+#rotates the graphic
  scale_fill_manual(values=c("#DE756A", "#68BEC4"),name="Algorithms")+
  theme(legend.position="bottom")
@