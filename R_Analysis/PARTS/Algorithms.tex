\subsection{\label{sec:algtest}Finding an optimal algorithm for flanging noise detection}
The aim of this part of the project is to implement an algorithm capable of telling whether a train is making flanging or squealing noise on a audio recording. This is a requisite for the next stage, which is analysing the performance of rail lubrification on noise reduction. We have proceeded in three steps :
\begin{itemize}
\item Hand selection of intervals on a subset of the samples

\item Development of a proto-algorithm

\item Optimisation of the proto-algorithm
\end{itemize}

\subsection{Hand selection of intervals}
We have selected by hands the intervals with noise on a small subset of samples (about twenty). We asked other people of our team to do the same. This gives us a subjective set of data to compare our algorithms. The {\bf subjective} part is very important as the perception of what an annoying noise is cannot be reduced solely to physical variables.

The process of selection was performed on an interface in PyQt created for this project. The python file to call to start this interface is {\tt run\_ CaseCreatorWidget}. The interface has two shapes: the first one is the simplest and most stable, it is only designed to select the cases; the second is not fully stable but implements an administrator environment that allows to review the intervals selected by the authors, review the algorithms and see the spectogram of the stft -- it is a faily long process, so be patient if you call it. 

\subsection{Development of a proto-algorithm} We have developped a simple algorithm for flanging noise based on the detection of steep change in band power ratio (BPR). The band power ratio is the relation of the low band frequencies to the high band frequencies taken on a small increment (dt) of the signal. This pattern leads to an algorithm with three variables: a delta time, a cutoff frequency (fc) and a threshold. This approach is described in general terms in Bullen and Jiang article for railways \citeyear{Bullen2010}\footnote{We found later that a similar algorithm was use for tonal bird sound recognition \autocite{Jancovic2011}}.

We computed the BPR for cutoff frequencies and delta times, first without worrying about the threshold. This gave us a list of BPRs to compare with the set of handmade data. We tested the combinations of the following fc and dt each giving a proto-algorithm (as it misses the threshold): fc in (2000, 3000, 3500, 4000, 45000) and dt in (0.02,0.05,0.1). This algorithm is named {\tt Zischendetetkt2} ({\tt Z2}) in the python files.

We noticed that one way to improve this algorithm would be to change the lower and upper bounds of the low and high bands (we noted them $fmin$ and $fmax$ in the code, especially in {\tt algorithm.py} from the {\tt kg} package). The default for {\tt Zischendetetkt2} was $fmin=100$. This could easily be raised to $300$. This would be one way to further improve our results. However this was not done at first and we shall use {\tt Z2} in the following article.

\subsection{Optimisation of the proto-algorithm} For all the previously obtained proto-algorithms, we computed the True Positive Rate (i.e. the ratio of increments that were rightly selected by the algorithm as containing noise) and the False Positive Rate (i.e. the ratio of increments wrongly selected as containing noise) with 300 thresholds slip between the smallest and highest BPR. With this we will compute the so-called Receiving Operating Characteristic (ROC). More can be found on this method in Swets, Dawes and Monahan popularisation article (2000). This procedure was performed with the python code {\tt main\_ analysis.py}. Then we merged the multiple files created by {\tt main\_ analysis.py} together in a csv file we called {\tt datamaous.csv}. The rows of this file correspond to a delta time of the discretisation performed with {\tt main\_ analysis.py}. The merge was done with the python script {\tt commuter.py}.

For each now-complete algorithm, we selected the best one, that is - for us - the one that is the farthest from the diagonal spanning from (0,0) to (1,1).,

This is how we proceeded:



{\tt find\_ best.R} contains two functions that basically do this:

\begin{lstlisting}[style=Rstyle, caption={\tt find\_ best.R},label=code:findbest]
TPFP_func<-function(df, threshold){
  #spec correspond to the BPR and disc to choise of the author : 1 is for flanging 0 for not flanging
  #tally function will count the TP, i.e. BPR is over the threshold and the author said it is flanging
  TP<-tally(filter(df, spec>threshold & disc==1))#True positives
  FP<-tally(filter(df, spec>threshold & disc==0))#False positives
  totP<-tally(filter(df,disc==1))#Total positives
  totF<-tally(filter(df,disc==0))#Total negatives
  if (totP>0 & totF>0){
    FPR<-FP/totF
    TPR=TP/totP
    d_ax<-(TPR+FPR)/2#compute closest point on main diagonal
    dist_ax<-sqrt( (d_ax-FPR)**2 + (d_ax-TPR)**2 )**2#compute euclidean distance to d_ax
  #returns a data.frame (empty if totP or totF is 0)
  }
}

find_best<-function(tff, authors=list(), qualities=list(),fixedthreshold=FALSE, bw=200){
  #iterate on algorithms
  ...
    #iterate on algorithms parameters
    ...
      #iterate on thresholds
      ...
      call TPFP_func
      add the best threshold (i.e. with dist_ax maximal) and its corresponding attributes to the return data.frame
}
\end{lstlisting}

This gave us the following table for our four authors -- the output give the name of the authors and the qualities selected, from 1 (bad) to 3 (good):











